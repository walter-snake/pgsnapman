#!/bin/bash

# pgsnap_cacheconfig: reads postgres server instances to backup from central configuration database
#                     must run on a backup worker, with passwordless (.pgpass does the job) to the
#                     central configuration database
# Actions taken:
#   1 connects to central configuration database
#   2 reads which pg instances should be backed up by this host
#   3 creates directory structure and writes connection info for every pg instance
#   4 reads jobs from central configuration database, creates directory structure per database and write cron job file
#
# You may refresh the configuration as often as you like, the actual backup proces runs entirely locally (does not need
# access to the central configuration database). 
# 
# Actual backups will be started by cron on this machine, each backup job is one cron entry, starts script: pgsnap_dump.

CONFIGFILE=/etc/pgsnapman/pgsnapman.config
VERBOSITY=$1

# ======================================
# Initialization
# ======================================

# Get the script directory (must do this first)
SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
SCRIPTPATH="$( cd -P "$( dirname "$SOURCE" )" && pwd )"

# Load functions
. ${SCRIPTPATH}/pgsnap_lib

# Set the config file
setconfigfile
. ${CONFIGFILE}

# ======================================
# Function definitions (script specific)
# ======================================

# Retrieves the worker configuration from the catalog database
function getworkerconfig {
  # Get worker configuration
  ${PGSCBIN}/psql -h ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,dns_name,comment, \
    cron_cacheconfig,cron_singlejob,cron_clean,cron_upload
    FROM vw_worker ORDER BY id" > $ROOTDIR/pgsnap_worker.cron
}

# Retrieves jobs from the configuration database
# $1 postgres host by id
# $2 instance snapshot location (full path)
function getjobs {
  # Get postgres worker information for workers managed by this backup worker (based on hostname) and cache the data
  # Make creating/replacing it an atomic operation, a dump could start while writing this file. 
  ${PGSCBIN}/psql -h ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,pgsnap_worker_id,pgsql_instance_id,dbname,dumptype,dumpschema, \
      cron,keep_daily,keep_weekly,keep_monthly,keep_yearly, \
      comment,status,jobtype, \
      pgsnap_worker_dns_name,pgsql_instance_dns_name,pgsql_instance_port,pgsql_instance_superuser,pgsnap_restorejob_id \
    FROM vw_dumpjob_worker_instance \
    WHERE pgsnap_worker_id = ${BUWORKERID} AND pgsql_instance_id = ${1} \
      AND jobtype = 'CRON' \
    ORDER BY id" > ${2}/dumpjobs.list.temp
  mv ${2}/dumpjobs.list.temp ${2}/dumpjobs.list
  if [ "$VERBOSITY" == "VERBOSE" ]; then
    echo "Job data for postgres instance id: "$1
    echo "-------------------------------------"
    echo "Snapshot base directory: "$2
    echo "id|pgsnap_worker_id|pgsql_instance_id|dbname|dumptype|dumpschema|cron|keep_daily|keep_weekly|keep_monthly|keep_yearly|comment|jobstatus|jobtype"
    cat ${2}/dumpjobs.list
    echo ""
  fi
}

# Set up directory structure for database dumps, based on data in the local cache (dumpjobs.list)
# $1 full path to a postgres instance snapshot directory
function preparejobs {
  if  [ "$VERBOSITY" == "VERBOSE" ]; then
    echo "Processing: "$1/dumpjobs.list
  fi
  echo "# pgsnapman pgsnap_dump jobs for "`basename $1` >> ${ROOTDIR}/cron_snapjobs.temp
  while read line; do
    jobid=$(echo "${line}" | cut -d '|' -f 1)
    pgsqlid=$(echo "${line}" | cut -d '|' -f 3)
    pgsqlhost=$(echo "${line}" | cut -d '|' -f 16)
    pgsqlport=$(echo ${line} | cut -d '|' -f 17)
    pgsqlsuperuser=$(echo "${line}" | cut -d '|' -f 18)
    dbname=$(echo "${line}" | cut -d '|' -f 4)
    butype=$(echo "${line}" | cut -d '|' -f 5)
    schema=$(echo "${line}" | cut -d '|' -f 6)
    cron=$(echo "${line}" | cut -d '|' -f 7)
    jobstatus=$(echo "${line}" | cut -d '|' -f 13)
    jobtype=$(echo "${line}" | cut -d '|' -f 14)
    restorejobid=$(echo "${line}" | cut -d '|' -f 19)
    # Set schema_part for the dump name
    if [ "${schema}" == "*" ]; then
      schema_part=""
    else
      dumpoptions="--schema="${schema}
      schema_part="."${schema}
    fi
    # Display a lot of data in verbose mode
    if  [ "$VERBOSITY" == "VERBOSE" ]; then
      echo "jobid:          ${jobid}"
      echo "pg id:          ${pgsqlid}"
      echo "pg host:        ${pgsqlhost}"
      echo "pg port:        ${pgsqlport}"
      echo "pg superuser:   ${pgsqlsuperuser}"
      echo "dbname:         ${dbname}"
      echo "butype:         ${butype}"
      echo "schema:         ${schema}"
      echo "cron:           ${cron}"
      echo "job status:     ${jobstatus}"
      echo "job type:       ${jobtype}"
      echo "dump options:   ${dumpoptions}"
      echo "restore job id: ${restorejobid}"
      echo ""
    fi

    # Create a cron job entry, only if active.
    # If postgres version could not be determined there was an error, but it will emitted as a warning at this stage.
    # The database may be available at the scheduled time, so the dump tool will repeat this test.
    PRE=""
    echo "INFO ${INITIMESTAMP} job id ${jobid} - ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}" >> ${ROOTDIR}/pgsnap_cacheconfig.log
    echo "# INFO pgsnapman job id ${jobid} - ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}" >> ${ROOTDIR}/cron_snapjobs.temp 
    # For active jobs, try to verify the database connection and postgresql version
    if [ "${jobstatus}" == "ACTIVE" ]; then
      # Check postgres instance version
      pgversion=`getpgversion ${pgsqlhost} ${pgsqlport} ${pgsqlsuperuser} ${dbname}`
      if [ "${pgversion}" == "" ]; then
        echo "WARNING ${INITIMESTAMP} job id ${jobid} - could not connect to postgres instance: ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part} - pg_dump version can not be verified, leaving job in place" >> ${ROOTDIR}/pgsnap_cacheconfig.log
      else
        # Get pg bin path for this version
        eval pgbinvar=PGBIN${pgversion}
        pgbin=${!pgbinvar}
      fi
      # Verify if pg_dump is available, disable when db connection could be made, version
      # checked and pg_dump not available (this is the only guaranteed problem, databases
      # could become available later).
      if [ "${pgversion}" != "" ]; then
        if [ ! -e ${pgbin}/pg_dump ]; then
          PRE="# "
          echo "ERROR ${INITIMESTAMP} job id ${jobid} - job is disabled as pg_dump could not be found, check pgbinxx paths in config file ${CONFIGFILE})" >> ${ROOTDIR}/pgsnap_cacheconfig.log
          echo "# ERROR pgsnapman job is disabled as pg_dump could not be found" >> ${ROOTDIR}/cron_snapjobs.temp
        fi
      fi
    fi
    # Emit warning on halted jobs
    if [ "${jobstatus}" == "HALTED" ]; then
      PRE="# "
      echo "WARNING ${INITIMESTAMP} job id ${jobid} - disabled by user (status HALTED): ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}" >> ${ROOTDIR}/pgsnap_cacheconfig.log
      echo "# WARNING pgsnapman job is disabled by user" >> ${ROOTDIR}/cron_snapjobs.temp
    fi
    # Write cron entry
    echo "${PRE}${cron} ${SCRIPTPATH}/pgsnap_dump ${1} ${jobid}" >> ${ROOTDIR}/cron_snapjobs.temp
    echo "INFO ${INITIMESTAMP} job id ${jobid} - cron entry created: ${PRE}${cron} ${SCRIPTPATH}/pgsnap_dump ${1} ${jobid}" >> ${ROOTDIR}/pgsnap_cacheconfig.log
  done < $1/dumpjobs.list
}

# ================================================================================
# MAIN
# ===============================================================================

setworkerid `basename ${0}`

# Started, write log entry
writeloginit `basename ${0}`

# Download de worker configuration
getworkerconfig

# Create the central pgsnapman dump directory
mkdir -p ${ROOTDIR}
mkdir -p ${DUMPSNAP}
mkdir -p ${DEDUPDATA}
mkdir -p ${ROOTDIR}/upload

# Create temp cron job file
echo "# pgsnapman ###################################################################" > ${ROOTDIR}/cron_snapjobs.temp
echo "# pgsnapman jobs created at ${INITIMESTAMP}" >> ${ROOTDIR}/cron_snapjobs.temp
echo "# pgsnapman ###################################################################" >> ${ROOTDIR}/cron_snapjobs.temp

# Add crontab entries for own job from worker config
while read line; do
  CACHECONFIGCRON=$(echo "${line}" | cut -d '|' -f 4)
  SINGLEJOBCRON=$(echo "${line}" | cut -d '|' -f 5)
  CLEANCRON=$(echo "${line}" | cut -d '|' -f 6)
  UPLOADCRON=$(echo "${line}" | cut -d '|' -f 7)
done < $ROOTDIR/pgsnap_worker.cron
rm  $ROOTDIR/pgsnap_worker.cron

echo "# pgsnapman worker jobs" >> ${ROOTDIR}/cron_snapjobs.temp
echo "${CACHECONFIGCRON} ${SCRIPTPATH}/pgsnap_cacheconfig" >> ${ROOTDIR}/cron_snapjobs.temp
echo "${CLEANCRON} ${SCRIPTPATH}/pgsnap_clean" >> ${ROOTDIR}/cron_snapjobs.temp
echo "${SINGLEJOBCRON} ${SCRIPTPATH}/pgsnap_singlejob" >> ${ROOTDIR}/cron_snapjobs.temp
echo "${UPLOADCRON} ${SCRIPTPATH}/pgsnap_upload" >> ${ROOTDIR}/cron_snapjobs.temp

# Get postgres instance information for all pgsql instances and cache the data (we need all of them,
# as a one time backup could also be inserted at any time for any host).
${PGSCBIN}/psql -h ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,dns_name,pgport,comment,status, \
  pgsql_superuser,bu_window_start,bu_window_end,pgsql_worker_id_default \
  FROM vw_instance ORDER BY id" > $ROOTDIR/pg_instances.list

# Display information
if [ "$VERBOSITY" == "VERBOSE" ]; then
  echo ''
  echo '+--------------------+'
  echo '| pgsnap_cacheconfig |'
  echo '+--------------------+'
  echo ''
  echo 'Config file:              '${CONFIGFILE}
  echo ''
  echo 'PgSnapman worker fqdn:    '${FQDN}
  echo 'PgSnapman worker id:      '${BUWORKERID}
  echo 'PgSnapman config cron     '${CACHECONFIGCRON}
  echo 'PgSnapman clean cron      '${CLEANCRON}
  echo 'PgSnapman single job cron '${SINGLEJOBCRON}
  echo ''
  echo 'Global pgsnapman catalog db'
  echo '  db:   '${PGSCDB}
  echo '  host: '${PGSCHOST}
  echo '  port: '${PGSCPORT}
  echo '  user: '${PGSCUSER}
  echo ''
  echo 'Postgres instances managed by pgsnapman:'
  echo 'id|dns_name|pgport|comment|status|pgsuperuser|bu_window_start|bu_window_end|pgsql_worker_id_default'
  cat $ROOTDIR/pg_instances.list
  echo ''
fi

# Create directories for every server listed, write connection info to file, ready to consume
echo "INFO ${INITIMESTAMP} init" > ${ROOTDIR}/pgsnap_cacheconfig.log
while read line; do
  pgid=$(echo "${line}" | cut -d '|' -f 1)
  pgdns=$(echo "${line}" | cut -d '|' -f 2)
  pgport=$(echo "${line}" | cut -d '|' -f 3)
  comment=$(echo "${line}" | cut -d '|' -f 4)
  pgstatus=$(echo "${line}" | cut -d '|' -f 5)
  pguser=$(echo "${line}" | cut -d '|' -f 6)
  mkdir -p ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}
  pgconninfo=${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/pgconninfo
  if [ "${pgdns}" == "local" ]; then
    echo "PGHOST=" > ${pgconninfo}
  else
    echo "PGHOST="${pgdns} > ${pgconninfo}
  fi
  echo "PGPORT="${pgport} >> ${pgconninfo}
  echo "PGUSER="${pguser} >> ${pgconninfo}
  if [ "${pgstatus}" == "ACTIVE" ]; then
    touch ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/active
    rm -f ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/halted
  else
    touch ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/halted
    rm -f ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/active
  fi
  getjobs ${pgid} ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}
  preparejobs ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}
done < $ROOTDIR/pg_instances.list

# Figure out if there are warnings/errors
if [ "`cat ${ROOTDIR}/pgsnap_cacheconfig.log | grep -E 'WARNING|ERROR'`" == "" ]; then
  JOBWARNINGS=" (without warnings)"
else
  JOBWARNINGS=" (with warnings)"
fi 
# Install new crontab, remove old pgsnap_dump entries, keep other entries
crontab -l > ${ROOTDIR}/crontab.previous
cat ${ROOTDIR}/crontab.previous | grep -v pgsnap | cat - ${ROOTDIR}/cron_snapjobs.temp > ${ROOTDIR}/crontab.latest
crontab ${ROOTDIR}/crontab.latest
if [ "$?" == "0" ]; then
  echo "INFO `date '+%Y%m%dT%H%M%S'` pgsnap_cacheconfig processing - crontab properly installed${JOBWARNINGS}" >> ${PGSNAPMANLOG}
else
  echo "ERROR `date '+%Y%m%dT%H%M%S'` pgsnap_cacheconfig processing - crontab failed to install (format errors)" >> ${PGSNAPMANLOG}
fi
rm ${ROOTDIR}/cron_snapjobs.temp


# Create message log for upload, based on logging 
cat  ${ROOTDIR}/pgsnap_cacheconfig.log | grep -E 'WARNING|ERROR' | awk '{printf( "pgsnap_cacheconfig\t"); for(i=1;i<=NF;i++) { printf($i); if (i==1 || i==2) {printf("\t")} else { printf(" ")}}; print ""}' > ${ROOTDIR}/pgsnap_cacheconfig.message.dat
ln -s -f ${ROOTDIR}/pgsnap_cacheconfig.message.dat ${ROOTDIR}/upload

echo "INFO `date '+%Y%m%dT%H%M%S'` pgsnap_cacheconfig finished" >> ${PGSNAPMANLOG}

exit 0

