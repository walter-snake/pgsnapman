#!/bin/bash

# pgsnap_cacheconfig: reads postgres server instances to backup from central configuration database
#                     must run on a backup worker, with passwordless (.pgpass does the job) to the
#                     central configuration database
#
# Commandline options
#   $1 verbosity [SILENT|VERBOSE]
#   $2 action/job type [INIT|CRON|SINGLE]
#   $3 job id for a single job run (required when action = SINGLE)
#
# Actions taken:
# ACTION=INIT
#   New pgsnapman data directory will be built.
#
# ACTION=CRON
#   Downloads and prepares pgsql instance dump directories and scheduled jobs.
#
# ACTION=SINGLE
#   Downloads and prepares pgsql instance dump directories and single run jobs.
#
#   1 connects to central configuration database
#   2 reads which pg instances should be backed up by this host
#   3 creates directory structure and writes connection info for every pg instance
#   4 reads jobs from central configuration database, creates directory structure per database and write cron job file
#
# You may refresh the configuration as often as you like, the actual backup proces runs entirely locally (does not need
# access to the central configuration database). 
# 
# Actual backups will be started by cron on this machine, each backup job is one cron entry, starts script: pgsnap_dump.

# ======================================
# Initialization
# ======================================
VERBOSITY=$1
ACTION=$2
SINGLEJOBID=$3

# Get the script directory (must do this first)
SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
SCRIPTPATH="$( cd -P "$( dirname "$SOURCE" )" && pwd )"

# Catalog database needed?
PGSCDB_REQUIRED=YES

# Load functions, will also perform initialization operations
. ${SCRIPTPATH}/pgsnap_lib

# ======================================
# Function definitions (script specific)
# ======================================

# Worker configuration functions
# ------------------------------------------------------------------------

# Init pgsnapman root directory
# Location read from global variable ROOTDIR
function initrootdir {
  echo "PgSNapMan ${ROOTDIR}"

  echo "Initializing data directory..."
  touch "${ROOTDIR}/status"
  if [ "$?" != "0" ]; then
    echo "ERROR PgSnapMan root directory not writable [${ROOTDIR}]"
    exit 1
  fi
  
  echo "  creating work directories"
  # Create the central pgsnapman dump directory
  mkdir -p ${DUMPSNAP}
  mkdir -p ${DEDUPDATA}
  mkdir -p ${ROOTDIR}/upload
  mkdir -p ${TEMPDIR}
  mkdir -p ${LOG}
  echo "Done."
}

# Install the new crontab
function installcrontab {
  # Install new crontab, remove old pgsnap_dump entries, keep other entries
  crontab -l > ${TEMPDIR}/crontab.previous
  cat ${TEMPDIR}/crontab.previous | grep -v pgsnap | cat - ${TEMPDIR}/cron_snapjobs.temp > ${TEMPDIR}/crontab.latest
  crontab ${TEMPDIR}/crontab.latest
  if [ "$?" == "0" ]; then
    snaplog "INFO" "processing - crontab properly installed${JOBWARNINGS}"
  else
    snaplog "ERROR" "processing - crontab failed to install (format errors)"
  fi
  rm ${TEMPDIR}/cron_snapjobs.temp
}

# Retrieves the worker configurations from the catalog database
# $1 backup worker id (numeric)
function getworkerconfig {
  # Get worker configuration
  local workercron=`${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,dns_name,comment, \
    cron_cacheconfig,cron_singlejob,cron_clean,cron_upload
    FROM vw_worker WHERE id = $1"`
  echo "${workercron}"
}

# Retrieve and set the worker configuration, inclusing creating cron jobs
function updateworkerconfig {

  # Create temp cron job file
  echo "# pgsnapman ###################################################################" > ${TEMPDIR}/cron_snapjobs.temp
  echo "# pgsnapman jobs created at ${INITIMESTAMP}" >> ${TEMPDIR}/cron_snapjobs.temp
  echo "# pgsnapman ###################################################################" >> ${TEMPDIR}/cron_snapjobs.temp

  # Add crontab entries for own cron job from worker config
  row=$(getworkerconfig ${BUWORKERID})
  CACHECONFIGCRON=$(getfieldvalue "${row}" 4)
  SINGLEJOBCRON=$(getfieldvalue "${row}" 5)
  CLEANCRON=$(getfieldvalue "${row}" 6)
  UPLOADCRON=$(getfieldvalue "${row}" 7)

  echo "# pgsnapman worker jobs" >> ${TEMPDIR}/cron_snapjobs.temp
  echo "${CACHECONFIGCRON} ${SCRIPTPATH}/pgsnap_cacheconfig" >> ${TEMPDIR}/cron_snapjobs.temp
  echo "${CLEANCRON} ${SCRIPTPATH}/pgsnap_clean" >> ${TEMPDIR}/cron_snapjobs.temp
  echo "${SINGLEJOBCRON} ${SCRIPTPATH}/pgsnap_singlejob" >> ${TEMPDIR}/cron_snapjobs.temp
  echo "${UPLOADCRON} ${SCRIPTPATH}/pgsnap_upload" >> ${TEMPDIR}/cron_snapjobs.temp
}

function updatepgsqlinstanceconfig {
  # Get postgres instance information for all pgsql instances and cache the data (we need all of them,
  # as a one time backup could also be inserted at any time for any host).
  ${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,dns_name,pgport,comment,status, \
    pgsql_superuser,bu_window_start,bu_window_end,pgsql_worker_id_default \
    FROM vw_instance ORDER BY id" > $ROOTDIR/pg_instances.list

  # Display information
  if [ "$VERBOSITY" == "VERBOSE" ]; then
    echo ""
    echo "+--------------------+"
    echo "| pgsnap_cacheconfig |"
    echo "+--------------------+"
    echo ""
    echo "Config file:              ${CONFIGFILE}"
    echo ""
    echo "PgSnapman worker fqdn:    ${FQDN}"
    echo "PgSnapman worker id:      ${BUWORKERID}"
    echo "PgSnapman config cron     ${CACHECONFIGCRON}"
    echo "PgSnapman clean cron      ${CLEANCRON}"
    echo "PgSnapman single job cron ${SINGLEJOBCRON}"
    echo ""
    echo "Global pgsnapman catalog db"
    echo "  db:   ${PGSCDB}"
    echo "  host: ${PGSCHOST}"
    echo "  port: ${PGSCPORT}"
    echo "  user: ${PGSCUSER}"
    echo ""
    echo "Postgres instances managed by pgsnapman:"
    echo "id|dns_name|pgport|comment|status|pgsuperuser|bu_window_start|bu_window_end|pgsql_worker_id_default"
    cat $ROOTDIR/pg_instances.list
    echo ""
  fi

  # Create directories for every server listed, write connection info to file, ready to consume
  log "INFO" "init" "NEW"
  while read line; do
    pgid=$(echo "${line}" | cut -d '|' -f 1)
    pgdns=$(echo "${line}" | cut -d '|' -f 2)
    pgport=$(echo "${line}" | cut -d '|' -f 3)
    comment=$(echo "${line}" | cut -d '|' -f 4)
    pgstatus=$(echo "${line}" | cut -d '|' -f 5)
    pguser=$(echo "${line}" | cut -d '|' -f 6)
    defworkerid=$(echo "${line}" | cut -d '|' -f 9)
    mkdir -p ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}
    echo ${pgstatus} > ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}/status
  done < $ROOTDIR/pg_instances.list
}

# Job management functions
# ------------------------------------------------------------------------

# Retrieves all databases from a postgres server instance, adds all those that are not listed in the dumpjobs table, with defaults
# - Does not depend on worker, all jobs are checked (a databas could purposely be put on another backup worker).
# - SINGLE jobs do count
# $1 = pg instance id
# $2 = pg dns name
# $3 = pg port
# $4 = pg user
function createdumpjobs {
  # Resolve host
  local fqdnhost=${2}
  local pgsqlhost=$(resolvepghost ${2})

  # Find the databases (exclude templates and all database that you cannot connect to)
  # Too lazy too look for the correct postgres binary version, not really important for this plain simple query 
  local DBS=`${PGSCBIN}/psql ${pgsqlhost} -p ${3} -U ${4} --dbname=${MAINTDB} -A -t -c "SELECT datname FROM pg_database WHERE datistemplate = false AND datallowconn = true;"` 2> /dev/null
  if [ "$?" != "0" ]; then
    return
  fi

  # Process the database list
  local c=0
  for line in ${DBS}; do
    local HASJOB=`${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -A -t -c "SELECT get_hasjob(${1}, '${line}');"`
    if [ "${HASJOB}" != "YES" ]; then
      echo "add database: ${fqdnhost}:${3}/${line}"
      local jobid=`${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -A -t -c "SELECT put_dumpjob(${1}, '${line}', 'auto added dump job');"`
      echo "new dump job created with id: ${jobid}"
      let "c = c + 1"
    fi
  done
  if [ ${c} -gt 0 ]; then 
    snaplog "INFO" "processing - auto job: added ${c} dump jobs on worker [${BUWORKERID}] for postgres instance [${fqdnhost}:${3}]"
  fi
}

# Retrieves cron jobs from the configuration database
# $1 postgres host by id
# $2 instance snapshot location (full path)
function getcronjobs {
  # Get postgres worker information for workers managed by this backup worker (based on hostname) and cache the data
  # Make creating/replacing it an atomic operation, a dump could start while writing this file. 
  ${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "SELECT id,pgsnap_worker_id,pgsql_instance_id,dbname,dumptype,dumpschema, \
      cron,keep_daily,keep_weekly,keep_monthly,keep_yearly, \
      comment,status,jobtype, \
      pgsnap_worker_dns_name,pgsql_instance_dns_name,pgsql_instance_port,pgsql_instance_superuser,pgsnap_restorejob_id,dumpoptions \
    FROM vw_dumpjob_worker_instance \
    WHERE pgsnap_worker_id = ${BUWORKERID} AND pgsql_instance_id = ${1} \
      AND jobtype = 'CRON' \
    ORDER BY id" > ${2}/dumpjobs.list.temp
  mv ${2}/dumpjobs.list.temp ${2}/dumpjobs.list
  if [ "$VERBOSITY" == "VERBOSE" ]; then
    echo "Job data for postgres instance id: "$1
    echo "-------------------------------------"
    echo "Snapshot base directory: "$2
    echo "id|pgsnap_worker_id|pgsql_instance_id|dbname|dumptype|dumpschema|cron|keep_daily|keep_weekly|keep_monthly|keep_yearly|comment|jobstatus|jobtype|dumpoptions"
    cat ${2}/dumpjobs.list
    echo ""
  fi
}

# Create the cron job entries for the jobs, based on data in the local cache (dumpjobs.list)
# $1 full path to a postgres instance snapshot directory
function createcronjobs {
  if  [ "$VERBOSITY" == "VERBOSE" ]; then
    echo "Creating cron jobs, processing: "$1/dumpjobs.list
  fi
  echo "# pgsnapman pgsnap_dump jobs for "`basename $1` >> ${TEMPDIR}/cron_snapjobs.temp
  while read line; do
    jobid=$(echo "${line}" | cut -d '|' -f 1)
    pgsqlid=$(echo "${line}" | cut -d '|' -f 3)
    pgsqldns=$(echo "${line}" | cut -d '|' -f 16)
    pgsqlport=$(echo ${line} | cut -d '|' -f 17)
    pgsqlsuperuser=$(echo "${line}" | cut -d '|' -f 18)
    dbname=$(echo "${line}" | cut -d '|' -f 4)
    butype=$(echo "${line}" | cut -d '|' -f 5)
    schema=$(echo "${line}" | cut -d '|' -f 6)
    dumpoptions=$(echo "${line}" | cut -d '|' -f 20)
    cron=$(echo "${line}" | cut -d '|' -f 7)
    jobstatus=$(echo "${line}" | cut -d '|' -f 13)
    jobtype=$(echo "${line}" | cut -d '|' -f 14)
    restorejobid=$(echo "${line}" | cut -d '|' -f 19)
    # Set schema_part for the dump name
    if [ "${schema}" == "*" ]; then
      schema_part=""
    else
      dumpoptions="--schema=${schema} ${dumpoptions}"
      schema_part="."${schema}
    fi

    # Resolve host
    pgsqlhost=$(resolvepghost ${pgsqldns})
    
    # Display a lot of data in verbose mode
    if  [ "$VERBOSITY" == "VERBOSE" ]; then
      echo "jobid:          ${jobid}"
      echo "pg id:          ${pgsqlid}"
      echo "pg host:        ${pgsqldns}"
      echo "pg port:        ${pgsqlport}"
      echo "pg superuser:   ${pgsqlsuperuser}"
      echo "dbname:         ${dbname}"
      echo "butype:         ${butype}"
      echo "schema:         ${schema}"
      echo "cron:           ${cron}"
      echo "job status:     ${jobstatus}"
      echo "job type:       ${jobtype}"
      echo "dump options:   ${dumpoptions}"
      echo "restore job id: ${restorejobid}"
      echo ""
    fi

    # Create a cron job entry, only if active.
    # If postgres version could not be determined there was an error, but it will emitted as a warning at this stage.
    # The database may be available at the scheduled time, so the dump tool will repeat this test.
    PRE=""
    log "INFO" "job id ${jobid} - ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}"
    echo "# INFO pgsnapman job id ${jobid} - ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}" >> ${TEMPDIR}/cron_snapjobs.temp 
    # For active jobs, try to verify the database connection and postgresql version
    if [ "${jobstatus}" == "ACTIVE" ]; then
      # Check postgres instance version
      pgversion=$(getpgversion "${pgsqlhost}" ${pgsqlport} ${pgsqlsuperuser} ${dbname})
      if [ "${pgversion}" == "" ]; then
        log "WARNING" "job id ${jobid} - could not connect to postgres instance: ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part} - pg_dump version can not be verified, leaving job in place"
      else
        # Get pg bin path for this version
        eval pgbinvar=PGBIN${pgversion}
        pgbin=${!pgbinvar}
      fi
      # Verify if pg_dump is available, disable when db connection could be made, version
      # checked and pg_dump not available (this is the only guaranteed problem, databases
      # could become available later).
      if [ "${pgversion}" != "" ]; then
        if [ ! -e ${pgbin}/pg_dump ]; then
          PRE="# "
          log "ERROR" "job id ${jobid} - job is disabled as pg_dump could not be found, check pgbinxx paths in config file ${CONFIGFILE})"
          echo "# ERROR pgsnapman job is disabled as pg_dump could not be found" >> ${TEMPDIR}/cron_snapjobs.temp
        fi
      fi
    fi
    # Emit warning on halted jobs
    if [ "${jobstatus}" == "HALTED" ]; then
      PRE="# "
      log "WARNING" "job id ${jobid} - disabled by user (status HALTED): ${pgsqlsuperuser}@${pgsqlhost}:${pgsqlport}/${dbname}${schema_part}"
      echo "# WARNING pgsnapman job is disabled by user" >> ${TEMPDIR}/cron_snapjobs.temp
    fi
    # Write cron entry
    echo "${PRE}${cron} ${SCRIPTPATH}/pgsnap_dump ${pgsqlid}_${pgsqldns}_${pgsqlport} ${jobid} SILENT CRON" >> ${TEMPDIR}/cron_snapjobs.temp
    log "INFO" "job id ${jobid} - cron entry created: ${PRE}${cron} ${SCRIPTPATH}/pgsnap_dump ${pgsqlid}_${pgsqldns}_${pgsqlport} ${jobid} SILENT CRON"
  done < $1/dumpjobs.list
}

# Entry point for rebuilding the cron job configuration, for every pgsql instance
#   checks for new databases
#   retrieve scheduled job information
#   creates the cron entries
function updatecronjobconfig {
  log "INFO" "init" "NEW"
  while read line; do
    # Need to collect the pgsql instance data
    pgid=$(echo "${line}" | cut -d '|' -f 1)
    pgdns=$(echo "${line}" | cut -d '|' -f 2)
    pgport=$(echo "${line}" | cut -d '|' -f 3)
    comment=$(echo "${line}" | cut -d '|' -f 4)
    pgstatus=$(echo "${line}" | cut -d '|' -f 5)
    pguser=$(echo "${line}" | cut -d '|' -f 6)
    defworkerid=$(echo "${line}" | cut -d '|' -f 9)

    # Check the pgsql_instances for unlisted databases, when instance is active and this backup worker is the default backup worker
    if [ "${AUTO_DUMPJOB}" == "YES" ] && [ "${defworkerid}" == "${BUWORKERID}" ] && [ "$(getinstancestatus ${pgid}_${pgdns}_${pgport})" == "ACTIVE" ]; then
      createdumpjobs ${pgid} ${pgdns} ${pgport} ${pguser}
    fi

    # Retrieve job list from server
    getcronjobs ${pgid} ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}

    # Prepare the jobs: create directories, cron entries
    createcronjobs ${DUMPSNAP}/${pgid}_${pgdns}_${pgport}
  done < $ROOTDIR/pg_instances.list
}

# Set up the job list for the single jobs that have to be executed (both dump and restore)
function updatesinglejobconfig {
  local sql="SELECT id,pgsnap_worker_id,pgsql_instance_id,dbname,dumptype,dumpschema \
    ,cron,keep_daily,keep_weekly,keep_monthly,keep_yearly \
    ,comment,status \
    ,jobtype,pgsnap_worker_dns_name,pgsql_instance_dns_name,pgsql_instance_port \
    ,pgsql_instance_superuser \
    ,pgsnap_restorejob_id,dumpoptions \
    FROM vw_dumpjob_worker_instance \
    WHERE id NOT IN (select jobid from pgsnap_singlerun where jobclass = 'DUMP') \
    AND pgsnap_worker_id = ${BUWORKERID} \
    AND jobtype = 'SINGLE' \
    ORDER BY id;"
  ${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "${sql}" > ${TEMPDIR}/${SINGLEJOBID}.singledumpjobs.list
  c=0
  while read line; do
    let "c = c + 1"
  done < ${TEMPDIR}/${SINGLEJOBID}.singledumpjobs.list
  if [ $c -eq 0 ]; then
    local result=NO
  else
    local result=YES
  fi
  echo ${result}
}

# ================================================================================
# MAIN
# ===============================================================================

# Tool log
TOOL_LOG=${ROOTDIR}/pgsnap_cacheconfig.log 

# Check action
if [  "${ACTION}" == "" ]; then
  echo "ERROR no action provided"
  exit 1
elif [ "${ACTION}" == "INIT" ]; then
  initrootdir

  # Get initial worker config (which will start up the regular cron jobs)
  echo "Reading worker settings from database for id [${BUWORKERID}]"
  echo "Update the worker configuration..."
  updateworkerconfig
  echo "Installed scheduled jobs."

  # Install the new crontab, so that worker cron jobs will fire up
  installcrontab

  # And done
  exit 0
fi

# Before running any other action, always update the worker and psql instance configuration, as
# the directories must be in place when starting a dump job.

# Depending on ACTION:
#  CRON will check for databases without jobs, download jobtype CRON jobs, prepare dirs and schedule them
#  SINGLE will download jobtype SINGLE jobs to a specified file, prepare dirs without writing cron entries
if [ "${ACTION}" == "CRON" ]; then
  updateworkerconfig
  updatepgsqlinstanceconfig
  updatecronjobconfig
  installcrontab
elif [ "${ACTION}" == "SINGLE" ]; then
  # First retrieve single jobs
  jobspending=$(updatesinglejobconfig)
  # If anything to do
  if [ "${jobspending}" == "YES" ]; then
    updatepgsqlinstanceconfig
  fi
fi

# Round up with a bit of logging
# Figure out if there are warnings/errors
if [ "`cat ${TOOL_LOG} | grep -E 'WARNING|ERROR'`" == "" ]; then
  JOBWARNINGS=" (without warnings)"
else
  JOBWARNINGS=" (with warnings)"
fi 

# Create message log for upload, based on logging 
cat  ${TOOL_LOG} | grep -E 'WARNING|ERROR' | awk '{for(i=1;i<=NF;i++) { printf($i); if (i>=1 && i <= 3) {printf("\t")} else { printf(" ")}}; print ""}' > ${ROOTDIR}/pgsnap_cacheconfig.message.dat
ln -s -f ${ROOTDIR}/pgsnap_cacheconfig.message.dat ${ROOTDIR}/upload

snaplog "INFO" "finished"

exit 0

