#!/bin/bash

# pgsnap_singlejob Checks for jobs marked as single run, downloads configuration and starts the jobs.
#
# $1 verbosity [VERBOSE|SILENT]

# ======================================
# Initialization
# ======================================
VERBOSITY=$1
# We must set the verbosity, as otherwise it propagates to the other tools that are started, and
# then the commandline options would shift.
if [ "${1}" == "" ]; then
  VERBOSITY="SILENT"
else
  VERBOSITY=$1
fi

# Get the script directory (must do this first)
SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
SCRIPTPATH="$( cd -P "$( dirname "$SOURCE" )" && pwd )"

# Catalog database needed?
PGSCDB_REQUIRED=YES

# Turn off tool init log (otherwise it would flood it, on a minutely check schedule)
LOGINIT=NO

# Load functions, will also perform initialization operations
. ${SCRIPTPATH}/pgsnap_lib

# =======================================
# Script specific functions
# =======================================

# Start dump jobs
function startdumpjobs {
  local line
  local jobfile=${TEMPDIR}/$$.singledumpjobs.list
  while read line; do
    jobid=$(getfieldvalue "${line}" 1)
    pgsqlid=$(getfieldvalue "${line}" 3)
    pgsqlhost=$(getfieldvalue "${line}" 16)
    pgsqlport=$(getfieldvalue "${line}" 17)
    pgsqlsuperuser=$(getfieldvalue "${line}" 18)
    dbname=$(getfieldvalue "${line}" 4)
    butype=$(getfieldvalue "${line}" 5)
    schema=$(getfieldvalue "${line}" 6)
    dumpoptions=$(getfieldvalue "${line}" 20)
    cron=$(getfieldvalue "${line}" 7)
    jobstatus=$(getfieldvalue "${line}" 13)
    jobtype=$(getfieldvalue "${line}" 14)
    restorejobid=$(getfieldvalue "${line}" 19)
    # Set schema_part for the dump name
    if [ "${schema}" == "*" ]; then
      schema_part=""
    else
      dumpoptions="--schema=${schema} ${dumpoptions}"
      schema_part="."${schema}
    fi

    # Display a lot of data in verbose mode
    if  [ "$VERBOSITY" == "VERBOSE" ]; then
      echo "job file:       ${jobfile}"
      echo "jobid:          ${jobid}"
      echo "pg id:          ${pgsqlid}"
      echo "pg host:        ${pgsqlhost}"
      echo "pg port:        ${pgsqlport}"
      echo "pg superuser:   ${pgsqlsuperuser}"
      echo "dbname:         ${dbname}"
      echo "butype:         ${butype}"
      echo "schema:         ${schema}"
      echo "cron:           ${cron} (SINGLE mode: ignored)"
      echo "job status:     ${jobstatus}"
      echo "job type:       ${jobtype}"
      echo "dump options:   ${dumpoptions}"
      echo "restore job id: ${restorejobid}"
      echo ""
      echo "Starting single run dump job"
      echo ""
    fi

    # Start the dump, in the background, and it should never start again, so we immediately mark it in the database
    # A job might (much) run longer than the interval between checks for jobs, can't use the catalog as the catalog
    # data could be uploaded much later, so immediately mark it in the database as started.
    setsinglerunstarted ${jobid} "DUMP"
    ${SCRIPTPATH}/pgsnap_dump ${pgsqlid}_${pgsqlhost}_${pgsqlport} ${jobid} ${VERBOSITY} SINGLE $$ &
  done < ${jobfile}
}

# =======================================
# MAIN
# =======================================
# Check if there are any single dump jobs that have not run

JOBID=0
# Check if already running, quit if so, exit code 0 (its not an error).
if [ "$(isjobrunning ${JOBID})" == "0" ]; then
  lock ${JOBID} "${0} ${1} ${2} ${3} ${4} ${5}"
else
  cleanupexit 0
fi

# Display information
if [ "$VERBOSITY" == "VERBOSE" ]; then
  echo ""
  echo "+--------------------+"
  echo "| pgsnap_singlejob   |"
  echo "+--------------------+"
  echo ""
  echo "Config file:              ${CONFIGFILE}"
  echo ""
  echo "PgSnapman worker fqdn:    ${FQDN}"
  echo "PgSnapman worker id:      ${BUWORKERID}"
  echo "PgSnapman config cron     ${CACHECONFIGCRON}"
  echo "PgSnapman clean cron      ${CLEANCRON}"
  echo "PgSnapman single job cron ${SINGLEJOBCRON}"
  echo ""
  echo "Global pgsnapman catalog db"
  echo "  db:   ${PGSCDB}"
  echo "  host: ${PGSCHOST}"
  echo "  port: ${PGSCPORT}"
  echo "  user: ${PGSCUSER}"
  echo ""
  echo "Postgres instances managed by pgsnapman:"
  echo "id|dns_name|pgport|comment|status|pgsuperuser|bu_window_start|bu_window_end|pgsql_worker_id_default"
  cat $ROOTDIR/pg_instances.list
  echo ""
fi

# Check if anything to do

if [ "$VERBOSITY" == "VERBOSE" ]; then
  echo "Checking for single run dump jobs"
fi
sql="select count(*) from vw_dumpjob_worker_instance where jobtype = 'SINGLE' and id not in (select jobid from pgsnap_singlerun where jobclass = 'DUMP');"
c=`${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -F '|' -A -t -c "${sql}"`
if [ $c -gt 0 ]; then
  if [ "$VERBOSITY" == "VERBOSE" ]; then
    echo "Starting cacheconfig to download single run configuration data"
  fi
  ${SCRIPTPATH}/pgsnap_cacheconfig SILENT SINGLE $$
  # Start the dumps
  snaplog "INFO" "single jobs found, starting"
  startdumpjobs
fi

# Be careful: do not clean up the dumpjob file, as it will be used by the pgsnap_dump script, and we don't know
# for sure when they're ready dealing with it. The pgsnap_clean tool will take care of it.

cleanupexit 0
