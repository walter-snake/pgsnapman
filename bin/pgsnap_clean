#!/bin/bash

# pgsnap_clean various routine maintenance operations for keeping the pgsnapman data directory clean
# - clean up old temp files
# - rotate and gzip log files
# - removing old backups according to retention policy
# - remove unused files from the dedup store (part of retention based cleaning, or separate full sanitize operation) 
#
# $1 VERBOSITY [SILENT|VERBOSE]
# $2 DEDUPCLEAN (full clean of dedup data store, optional)
# $3 BATCH (run full DEDUPCLEAN in batch mode, optional when $2=DEDUPCLEAN)
#

# ======================================
# Initialization
# ======================================
VERBOSITY=$1

# Get the script directory (must do this first)
SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
SCRIPTPATH="$( cd -P "$( dirname "$SOURCE" )" && pwd )"

# Catalog database needed?
PGSCDB_REQUIRED=YES

# Load functions, will also perform initialization operations
. ${SCRIPTPATH}/pgsnap_lib

# Check verbosity
if [[ ! "$1" =~ SILENT|VERBOSE ]]; then
  echo "ERROR verbosity must be set"
  cleanupexit 1
fi

# =======================================
# Functions
# =======================================

# Retrieve all jobs with catalog entries, and retention info from the jobs table.
# writes a temp file ${TEMPDIR}/$$.0.catalogjobinfo.list
# (no parameters)
function getcatalogjobinfo {
  # Obtain retention policy values for deleted jobs
  local sql="select get_default('retention_on_delete');"
  local defretpol=$( catdbquery "$sql" )
  if [ "$defretpol" == "" ]; then
    defretpol="7|1|0|0"
  fi
  # Request retention info for all jobs present in the catalog (including those that are deleted from the dumpjob table)
  sql="select distinct c.pgsnap_dumpjob_id, coalesce(j.keep_daily, $(getfieldvalue $defretpol 1)), coalesce(j.keep_weekly, $(getfieldvalue $defretpol 2)) \
      , coalesce(j.keep_monthly,$(getfieldvalue $defretpol 3)), coalesce(j.keep_yearly,$(getfieldvalue $defretpol 4)) \
    from pgsnap_catalog c \
    left join pgsnap_dumpjob j \
      on j.id = c.pgsnap_dumpjob_id;"
  catdbquerytofile "${sql}" "${TEMPDIR}/$$.0.catalogjobinfo.list"
}

# Removes an entry from the catalog list
# $1 id of the catalog entry
function removefromcatalogdb {
  local sql="select del_catalog($1)";
  catdbexecute "${sql}"
}

# Removes an entry from the catalog list
# $1 id of the catalog entry
function setcatalogdbstatus {
  local sql="select set_catalogstatus($1, '$2')";
  catdbexecute "${sql}"
}

# Clean up a specific job based on provided retention settings
# $1 jobid
# $2 keep_dayly
# $3 keep_weekly
# $4 keep_monthly
# #5 keep_yearly
function cleanupjob {
  local line
  echo "${INITIMESTAMP} Catalog ids to keep for job id: $1" >> ${LOGDIR}/pgsnap_clean.keepcatids.log
  local sql="select c.id, c.starttime, c.bu_name, c.bu_location || '/' || c.bu_name as full_path from pgsnap_catalog c where c.pgsnap_dumpjob_id = $1 AND c.id not in (select id from get_keep_catjobid('`date '+%Y%m%dT%H%M%S%z'`', $1, $2, $3, $4, $5) as (id integer));"
# FOR DEBUGGING
#  local sql="select c.id, c.starttime, c.bu_name, c.bu_location || '/' || c.bu_name as full_path from pgsnap_catalog c where c.pgsnap_dumpjob_id = $1 AND c.id not in (select id from get_keep_catjobid('`date '+%Y%m%dT%H%M%S%z'`', $1, 0, 0, 0, 0) as (id integer));"
# END DEBUGGING
  # We'll leave this psql request here, because of special logging
  ${PGSCBIN}/psql ${PGSCHOST} -p ${PGSCPORT} -U ${PGSCUSER} --dbname=${PGSCDB} -c "$sql" -A -t -F '|' --output=${TEMPDIR}/$$.removedumps.list 2>> ${LOGDIR}/pgsnap_clean.keepcatids.log
  # Loop through all catalog entries, and remove them
  while read line; do
    # Set status to REMOVING, so you know you shouldn't start a restore job from this one.
    local path="$(getfieldvalue "${line}" 4)"
    local path=`echo "${path}" | sed -E 's/.sql.gz$//g'`
    # Check if the path is safe, if so proceed
    if [ "$(issafetoremove "${path}")" == "NO" ]; then
      talk "WARNING path unsafe to remove [${path}]"
    elif [ "$(isrestorerunning "${path}")" == "YES" ]; then
      talk "WARNING restore job running [${path}]"
    else
      talk "INFO remove from catalog: $(getfieldvalue "${line}" 1) $(getfieldvalue "${line}" 2) $(getfieldvalue "${line}" 3)"
      log "INFO" "remove from catalog: $(getfieldvalue "${line}" 1) $(getfieldvalue "${line}" 2) $(getfieldvalue "${line}" 3)"
      setcatalogdbstatus $(getfieldvalue "${line}" 1) "REMOVING"
      local checksumfile=${path}.chksum
      # Possibly slow when cleaning up tons of backups, as files will be checked multiple times. But, this is
      # only the case when there are indeed many links, and typically when cleaning on a daily basis, it is the
      # faster solution, as only a handful of probably non-identical database dumps will be cleaned (one per database).
      # 1. Remove the data files (step 1), still keeping the chksum etc
      rm -rf ${path}/*.dat*
      # 2. Clean up dedup store
      dedupstore_clean ${checksumfile}
      # Remove everything else
      rm -rf ${path}*
      # Remove the entry from the catalog db altogether
      removefromcatalogdb $(getfieldvalue "${line}" 1)
    fi
  done < ${TEMPDIR}/$$.removedumps.list
  rm -f ${TEMPDIR}/$$.removedumps.list
}

# Verify if a path can be safely removed
function issafetoremove {
  mydir="$1"
  minlength=6
  # Many checks on the path, to be sure we're not going to remove something that hurts the server
  if [ `echo ${#mydir}` -lt ${minlength} ]; then
    log "ERROR" "path too short [$1]"
  fi

  if [[ "${mydir}" =~ \/\.\.\/ ]]; then
    log "ERROR" "path contains /../ [$1]"
  fi

  if [[ ! "${mydir}" =~ ^${DUMPSNAP}/ ]]; then
    log "ERROR" "path does not start with: ${DUMPSNAP} [$1]"
  fi
  # All in one, go-no-go, echo is function output: 'return' value
  if [ `echo ${#mydir}` -ge ${minlength} ] && [[ ! "${mydir}" =~ \/\.\.\/ ]] && [[ "${mydir}" =~ ^${DUMPSNAP}/ ]]; then
    echo "YES"
  else
    echo "NO"
  fi
}

# Check if a restore job is running
# $1 full path (without extension) of the dump to verify if no restore is running
# checked through the detour of using the lock files instead of a dedicated restore
# lock in the dump dir, as this stuff gets cleaned up automatically
function isrestorerunning {
  # Loop through all pgsnap_restore files, read contents and compare
  local restorejobs=`find ${TEMPDIR} -name '*.pgsnap_restore.lock'`
  for rj in ${restorejobs}; do
    if [ "`cat ${rj}`" == "${1}" ]; then
      echo "YES"
    else
      echo "NO"
    fi
  done
}

# Verify a single data file in the dedupstore, check if it can be removed.
# $1 file with checksums (1st column) to verify and clean if no links are present anymore
function dedupstore_clean {
  local rmfile
  local line
  if [ ! -e "${1}" ]; then
    return
  fi
  excludedir=$(echo "${1}" | sed 's/.chksum//')
  log "INFO" "processing dedupdata: $1"
  if [ "${VERBOSITY}" == "VERBOSE" ]; then
    echo "INFO processing dedupdata: $1"
    echo "INFO searching for links"
    echo "INFO checked files (* marked for removal)"
  fi
  # Create new empty temo file to store files to remove in
  echo -n "" > ${TEMPDIR}/$$.0.datafiles.rm
  # Build list of files to remove
  while read line; do
    chksum=$(getfieldvalue "${line}" 1 " ")
    local idxpath="$(getdedupindexedpath ${chksum})"
    c=`find -L ${DUMPSNAP}/ -samefile ${idxpath} | wc -l | sed 's/ //g'`
    if [ $c -eq 0 ]; then
      echo "$line" >> ${TEMPDIR}/$$.0.datafiles.rm
    fi
    if [ "${VERBOSITY}" == "VERBOSE" ]; then
      if [ $c -eq 0 ]; then
        echo "* `basename $line` - link count: $c"
      else
        echo "  `basename ${line}` - link count: $c"
      fi
    fi
  done < ${1}
  talk "-------------------"
  # Go through list of files to remove from dedupstore
  if [ -e "${TEMPDIR}/$$.0.datafiles.rm" ]; then
    while read line; do
      chksum=$(getfieldvalue "${line}" 1 " ")
      rmfile=$(getdedupindexedpath "${chksum}")
      talk "* remove file: ${rmfile}"
      #rm -f "${rmfile}"
    done < ${TEMPDIR}/$$.0.datafiles.rm
  fi
}

# Get the full path in the dedup store for a specified checksum
# $1 checksum
function getdedupindexedpath {
  local index1=${line:0:1}
  local index2=${line:1:1}
  local fileindex=${DEDUPDATA}/${index1}/${index2}
  echo ${fileindex}/${1}
}

# Full catalog clean up, based on retention policy
# Get the jobs that have catalog entries, together with retention info
# Calls the subsequent job cleaning operation, which includes dedup store cleaning.
# (no parameters)
function cleanupcatalog {
  local line
  # Get the jobs that have catalog entries, together with retention info, use temp file with results
  getcatalogjobinfo
  # Go through results, clean up
  while read line; do
    cleanupjob $(getfieldvalue "${line}" 1) $(getfieldvalue "${line}" 2) $(getfieldvalue "${line}" 3) $(getfieldvalue "${line}" 4) $(getfieldvalue "${line}" 5) 
  done < ${TEMPDIR}/$$.0.catalogjobinfo.list
}

# Full clean up of the deduplication store, forced by comparing link pointers with
# available data files.
function dedupstore_fullclean {
  local line
  # Check links to every file, as long as there's one, we leave it in place.
  find ${DEDUPDATA}/* -type f > ${TEMPDIR}/$$.0.datafiles.list
  if [ "$?" != 0 ]; then
    talk "ERROR find errors occured"
    return
  fi
  tc=0
  lc=0
  log "INFO" "searching for links"
  talk "------------------------------------"
  talk "Checked files (* marked for removal)"
  while read line; do
    c=`find -L ${DUMPSNAP}/ -samefile ${line} | wc -l | sed 's/ //g'`
    let "lc = lc + c"
    if [ $c -eq 0 ]; then
      echo "$line" >> ${TEMPDIR}/$$.0.datafiles.rm
      let "tc = tc + 1"
    fi
    if [ "${VERBOSITY}" == "VERBOSE" ]; then
      if [ $c -eq 0 ]; then
        echo "* `basename ${line}` - link count: $c"
      else
        echo "  `basename ${line}` - link count: $c"
      fi
    fi
  done < ${TEMPDIR}/$$.0.datafiles.list

  # An extra check: if no links are found, nothing will be deleted. This makes it impossible
  # that files will be deleted when someone manually removed the links, 
  if [ $lc -eq 0 ]; then
    talk "No links are found, we're not deleting anything as a precaution measure"
    log "WARNING" "no links are found, we're not deleting anything as a precaution measure"
    return
  fi

  # Check if anything to do, depending on batch mode or not asks for confirmation.
  if [ ! -e ${TEMPDIR}/$$.0.datafiles.rm ]; then
    talk "Nothing to do"
    log "INFO" "nothing to do"
  else
    if [ "${BATCHMODE}" != "BATCH" ]; then
      while true; do
        read -p "Do you wish to remove $tc files??" yn
        case $yn in
          [Yy]* ) break;;
          [Nn]* ) cleanupexit;;
          * ) echo "Please answer yes or no.";;
        esac
      done
    fi

    log "INFO" "removing $tc files"
    while read line; do
      rm -f ${line} 
    done < ${TEMPDIR}/$$.0.datafiles.rm
  fi
}

# =======================================
# MAIN
# =======================================

# Check if already running, quit if so, exit code 0 (its not an error).
JOBID=0
if [ "$(isjobrunning ${JOBID})" == "0" ]; then
  lock ${JOBID} "${0} ${1} ${2} ${3} ${4} ${5}"
else
  cleanupexit 0
fi

# Validate the DEDUPstore, if it does not exist we'll immediately exist
# Otherwise we're in trouble (especially the snapshot dir, where we
# must find the links: no link, data gone). 
if [ ! -d ${DUMPSNAP} ]; then
  talk "The snapshot directory does not exist, unsafe to continue."
  snaplog "ERROR" "init  - the snapshot directory does not exist, unsafe to continue."
  cleanupexit 1
fi

# Set the tool log
TOOL_LOG=${LOGDIR}/pgsnap_clean.log

# Batch mode
BATCHMODE=$3

# Force full dedup store cleaning
if [ "$2" == "DEDUPCLEAN" ]; then

  # Normally, cleaning the dedup store occurs while cleaning up the catalog. This may however fail when
  # someone manually removed a backup, and then the files belonging to that particular backup only will
  # never be checked again. Thus, it is made possible to perform a full dedupstore clean up, by calling
  # dedupstore_fullclean.
  # To be run from the commandline, nothing will be logged (messages all stdout).
  talk "Performing full deduplication store cleanup"
  snaplog "INFO" "init - full dedupstore scan and clean"
  dedupstore_fullclean
else
  # Normal, scheduled maintenance mode
  talk "Performing maintenance clean up by backup"

  # Clean up temp files from previously running jobs (unclean exit, checks for running by pid)
  find ${TEMPDIR} -type f -name '*' | grep -v crontab >> ${TEMPDIR}/$$.0.clean_running.temp
  while read line; do
    chkpid=$(echo `basename $line` | cut -d '.' -f 1)
    ps -p $chkpid &> /dev/null
    if [ "$?" == "1" ]; then
      rm -f $line
    fi
  done < ${TEMPDIR}/$$.0.clean_running.temp

  # Log file rotation
  filetimestamp=`date '+%Y%m%dT%H%M%S%z'`
  rotate=`find ${LOGDIR} -type f -name '*.log' -size +${MAXLOGSIZE}`
  for f in ${rotate}; do
    if [ "${f}" != "" ]; then
      mv "${f}" "${LOGDIR}/`basename ${f}`.${filetimestamp}"
      gzip "${LOGDIR}/`basename ${f}`.${filetimestamp}"
    fi
  done

  # Restore log clean up
  find ${LOGDIR} -type f -name '*.pgsnap_restore.log' -mtime ${KEEPRESTORELOG} -delete

  # Retention policy-cleaning
  cleanupcatalog

  # Fire up verification job when in SILENT mode
  if [ "${VERBOSITY}" == "SILENT" ]; then 
    talk "Starting verification"
    ${SCRIPTPATH}/pgsnap_verify ${VERBOSITY} &
  fi
fi
cleanupexit 0


